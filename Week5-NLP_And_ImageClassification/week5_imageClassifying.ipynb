{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: regex in c:\\python3\\lib\\site-packages (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\python3\\lib\\site-packages (4.62.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\python3\\lib\\site-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: colorama in c:\\python3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script ftfy.exe is installed in 'C:\\Users\\re19017\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\python3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\re19017\\appdata\\local\\temp\\pip-req-build-iuo2sz6x\n",
      "Requirement already satisfied: ftfy in c:\\users\\re19017\\appdata\\roaming\\python\\python39\\site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\python3\\lib\\site-packages (from clip==1.0) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\python3\\lib\\site-packages (from clip==1.0) (4.62.0)\n",
      "Requirement already satisfied: torch in c:\\python3\\lib\\site-packages (from clip==1.0) (1.9.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\python3\\lib\\site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\python3\\lib\\site-packages (from torch->clip==1.0) (3.7.4.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.0.1-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Requirement already satisfied: requests in c:\\python3\\lib\\site-packages (from torchvision->clip==1.0) (2.26.0)\n",
      "Requirement already satisfied: numpy in c:\\python3\\lib\\site-packages (from torchvision->clip==1.0) (1.19.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2021.5.30)\n",
      "Requirement already satisfied: colorama in c:\\python3\\lib\\site-packages (from tqdm->clip==1.0) (0.4.4)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py): started\n",
      "  Building wheel for clip (setup.py): finished with status 'done'\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369272 sha256=b20432469e7d744f9f195e3b0fc8e4d9580ca12d404365320c9c3b191cea2be4\n",
      "  Stored in directory: C:\\Users\\re19017\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k4vv3yen\\wheels\\c8\\e4\\e1\\11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n",
      "Successfully built clip\n",
      "Installing collected packages: torch, pillow, torchvision, clip\n",
      "Successfully installed clip-1.0 pillow-9.0.1 torch-1.11.0 torchvision-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/openai/CLIP.git 'C:\\Users\\re19017\\AppData\\Local\\Temp\\pip-req-build-iuo2sz6x'\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\re19017\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\python3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Description</th>\n",
       "      <th>Link</th>\n",
       "      <th>Article_Title</th>\n",
       "      <th>Article_URL</th>\n",
       "      <th>Article_Text</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid delivery's rapid rise has led to tension...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Dutch cities temporarily banned 10-minute deli...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/24/dutch...</td>\n",
       "      <td>['Noise, reckless cycling and blacked-out wind...</td>\n",
       "      <td>['company', 'shop', 'freeze', 'rotterdam', 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start-up conference Step in Dubai Internet City.</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>How Dubai Internet City is becoming a hub for ...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/23/how-d...</td>\n",
       "      <td>['Khazna, one of the largest data centre infra...</td>\n",
       "      <td>['khazna', 'centre', 'internet', 'data', 'incr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta CEO Mark Zuckerberg said the company's co...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Ahoy, Metamates! Meta continues rebranding eff...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/16/ahoy-...</td>\n",
       "      <td>[\"Employees at Facebook's parent company Meta ...</td>\n",
       "      <td>['employee', 'company', 'privacy', 'use', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carolyn Kaster/AP Photo</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Ahoy, Metamates! Meta continues rebranding eff...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/16/ahoy-...</td>\n",
       "      <td>[\"Employees at Facebook's parent company Meta ...</td>\n",
       "      <td>['employee', 'company', 'privacy', 'use', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Choosing a green pension could be better for t...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Green pensions could be the â€˜most powerful wea...</td>\n",
       "      <td>https://www.euronews.com/green/2022/02/15/gree...</td>\n",
       "      <td>['Switching to a sustainable pension could be ...</td>\n",
       "      <td>['company', 'invest', 'use', 'matter', 'pensio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Image_Description  \\\n",
       "0  Rapid delivery's rapid rise has led to tension...   \n",
       "1  Start-up conference Step in Dubai Internet City.    \n",
       "2  Meta CEO Mark Zuckerberg said the company's co...   \n",
       "3                            Carolyn Kaster/AP Photo   \n",
       "4  Choosing a green pension could be better for t...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://static.euronews.com/articles/stories/0...   \n",
       "1  https://static.euronews.com/articles/stories/0...   \n",
       "2  https://static.euronews.com/articles/stories/0...   \n",
       "3  https://static.euronews.com/articles/stories/0...   \n",
       "4  https://static.euronews.com/articles/stories/0...   \n",
       "\n",
       "                                       Article_Title  \\\n",
       "0  Dutch cities temporarily banned 10-minute deli...   \n",
       "1  How Dubai Internet City is becoming a hub for ...   \n",
       "2  Ahoy, Metamates! Meta continues rebranding eff...   \n",
       "3  Ahoy, Metamates! Meta continues rebranding eff...   \n",
       "4  Green pensions could be the â€˜most powerful wea...   \n",
       "\n",
       "                                         Article_URL  \\\n",
       "0  https://www.euronews.com/next/2022/02/24/dutch...   \n",
       "1  https://www.euronews.com/next/2022/02/23/how-d...   \n",
       "2  https://www.euronews.com/next/2022/02/16/ahoy-...   \n",
       "3  https://www.euronews.com/next/2022/02/16/ahoy-...   \n",
       "4  https://www.euronews.com/green/2022/02/15/gree...   \n",
       "\n",
       "                                        Article_Text  \\\n",
       "0  ['Noise, reckless cycling and blacked-out wind...   \n",
       "1  ['Khazna, one of the largest data centre infra...   \n",
       "2  [\"Employees at Facebook's parent company Meta ...   \n",
       "3  [\"Employees at Facebook's parent company Meta ...   \n",
       "4  ['Switching to a sustainable pension could be ...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  ['company', 'shop', 'freeze', 'rotterdam', 'da...  \n",
       "1  ['khazna', 'centre', 'internet', 'data', 'incr...  \n",
       "2  ['employee', 'company', 'privacy', 'use', 'met...  \n",
       "3  ['employee', 'company', 'privacy', 'use', 'met...  \n",
       "4  ['company', 'invest', 'use', 'matter', 'pensio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('week5.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "theImages = []\n",
    "theKeywords = [] \n",
    "sample = dataset.sample(20)\n",
    "for imagepath, key in zip( sample[\"Link\"], sample['Keywords'] ) :\n",
    "    #print(\\\"Image: \\\", imagepath)\n",
    "    req = urllib.request.urlopen(imagepath)\n",
    "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "    im = cv2.imdecode(arr, -1)\n",
    "    theImages.append(im)\n",
    "    theKeywords.append(key)\n",
    "    time.sleep(3)\n",
    "\n",
    "filePaths = []\n",
    "for i in range(len(theImages)):\n",
    "    if theImages[i] is not None:\n",
    "        fn = 'images/' + str(i) + '.png'\n",
    "        filePaths.append(fn)\n",
    "        #print(fn, theImages[i])\n",
    "        cv2.imwrite(fn, theImages[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['child',\n",
       " 'furniture',\n",
       " 'company',\n",
       " 'recycle',\n",
       " 'vanbriel',\n",
       " 'product',\n",
       " 'planet',\n",
       " 'business',\n",
       " 'joris',\n",
       " 'toy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(\"\\w+\", theKeywords[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.01665869 0.19420391 0.02826662 0.00902828 0.28671438 0.08108789\n",
      "  0.03962763 0.02636237 0.2253054  0.0331996  0.05954532]]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "keys = re.findall(\"\\w+\", theKeywords[0]) \n",
    "keys.append(\"person\")\n",
    "image = preprocess(Image.open(filePaths[0])).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(keys).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(probs)\n",
    "np.where(probs[0] == probs[0].max())[0][0]\n",
    "theText = [\"a person\", \"a dog\", \"a cat\"]\n",
    "theText[np.where(probs[0] == probs[0].max())[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/0.png',\n",
       " 'images/1.png',\n",
       " 'images/10.png',\n",
       " 'images/100.png',\n",
       " 'images/101.png',\n",
       " 'images/102.png',\n",
       " 'images/103.png',\n",
       " 'images/104.png',\n",
       " 'images/105.png',\n",
       " 'images/106.png',\n",
       " 'images/107.png',\n",
       " 'images/108.png',\n",
       " 'images/109.png',\n",
       " 'images/11.png',\n",
       " 'images/110.png',\n",
       " 'images/111.png',\n",
       " 'images/112.png',\n",
       " 'images/113.png',\n",
       " 'images/114.png',\n",
       " 'images/115.png',\n",
       " 'images/116.png',\n",
       " 'images/12.png',\n",
       " 'images/13.png',\n",
       " 'images/14.png',\n",
       " 'images/15.png',\n",
       " 'images/16.png',\n",
       " 'images/17.png',\n",
       " 'images/18.png',\n",
       " 'images/19.png',\n",
       " 'images/2.png',\n",
       " 'images/21.png',\n",
       " 'images/22.png',\n",
       " 'images/23.png',\n",
       " 'images/24.png',\n",
       " 'images/25.png',\n",
       " 'images/26.png',\n",
       " 'images/27.png',\n",
       " 'images/28.png',\n",
       " 'images/29.png',\n",
       " 'images/30.png',\n",
       " 'images/31.png',\n",
       " 'images/32.png',\n",
       " 'images/33.png',\n",
       " 'images/34.png',\n",
       " 'images/35.png',\n",
       " 'images/36.png',\n",
       " 'images/37.png',\n",
       " 'images/38.png',\n",
       " 'images/39.png',\n",
       " 'images/4.png',\n",
       " 'images/40.png',\n",
       " 'images/41.png',\n",
       " 'images/42.png',\n",
       " 'images/43.png',\n",
       " 'images/44.png',\n",
       " 'images/45.png',\n",
       " 'images/46.png',\n",
       " 'images/47.png',\n",
       " 'images/48.png',\n",
       " 'images/49.png',\n",
       " 'images/5.png',\n",
       " 'images/50.png',\n",
       " 'images/51.png',\n",
       " 'images/52.png',\n",
       " 'images/53.png',\n",
       " 'images/54.png',\n",
       " 'images/55.png',\n",
       " 'images/56.png',\n",
       " 'images/57.png',\n",
       " 'images/58.png',\n",
       " 'images/59.png',\n",
       " 'images/6.png',\n",
       " 'images/60.png',\n",
       " 'images/61.png',\n",
       " 'images/62.png',\n",
       " 'images/63.png',\n",
       " 'images/64.png',\n",
       " 'images/65.png',\n",
       " 'images/66.png',\n",
       " 'images/67.png',\n",
       " 'images/68.png',\n",
       " 'images/69.png',\n",
       " 'images/7.png',\n",
       " 'images/70.png',\n",
       " 'images/71.png',\n",
       " 'images/72.png',\n",
       " 'images/73.png',\n",
       " 'images/74.png',\n",
       " 'images/75.png',\n",
       " 'images/76.png',\n",
       " 'images/77.png',\n",
       " 'images/78.png',\n",
       " 'images/79.png',\n",
       " 'images/8.png',\n",
       " 'images/80.png',\n",
       " 'images/81.png',\n",
       " 'images/82.png',\n",
       " 'images/83.png',\n",
       " 'images/84.png',\n",
       " 'images/85.png',\n",
       " 'images/86.png',\n",
       " 'images/87.png',\n",
       " 'images/88.png',\n",
       " 'images/89.png',\n",
       " 'images/9.png',\n",
       " 'images/90.png',\n",
       " 'images/91.png',\n",
       " 'images/92.png',\n",
       " 'images/93.png',\n",
       " 'images/94.png',\n",
       " 'images/95.png',\n",
       " 'images/96.png',\n",
       " 'images/97.png',\n",
       " 'images/98.png',\n",
       " 'images/99.png']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageFilenames = []\n",
    "for f in os.listdir('images'):\n",
    "    imageFilenames.append('images/'+f)\n",
    "    \n",
    "imageFilenames.sort()\n",
    "imageFilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: images/0.png     Label probs: [[0.01665869 0.19420391 0.02826662 0.00902828 0.28671438 0.08108789\n",
      "  0.03962763 0.02636237 0.2253054  0.0331996  0.05954532]]\n",
      "Label:  vanbriel\n",
      "\n",
      "Filename: images/1.png     Label probs: [[0.17202117 0.19067247 0.09597183 0.17853592 0.05237311 0.17456755\n",
      "  0.09446716 0.04139081]]\n",
      "Label:  entrepreneur\n",
      "\n",
      "Filename: images/2.png     Label probs: [[0.33175248 0.03803428 0.00589781 0.008564   0.5963856  0.00891118\n",
      "  0.01045471]]\n",
      "Label:  shopper\n",
      "\n",
      "Filename: images/3.png     Label probs: [[9.72401910e-03 4.86902078e-04 9.54297304e-01 5.21288021e-03\n",
      "  9.79406293e-03 1.45723615e-02 5.91252465e-03]]\n",
      "Label:  ireland\n",
      "\n",
      "Filename: images/4.png     Label probs: [[0.05762423 0.0862273  0.05676711 0.0344808  0.07155424 0.13480136\n",
      "  0.03246328 0.12635887 0.07164997 0.2272038  0.10086897]]\n",
      "Label:  mol\n",
      "\n",
      "Filename: images/5.png     Label probs: [[0.01226546 0.30095688 0.04362405 0.07602143 0.08810082 0.28214264\n",
      "  0.07414858 0.01326635 0.00307582 0.10639806]]\n",
      "Label:  company\n",
      "\n",
      "Filename: images/6.png     Label probs: [[0.03035334 0.1245153  0.00853216 0.00345582 0.00209706 0.01378989\n",
      "  0.011443   0.7848383  0.02097508]]\n",
      "Label:  work\n",
      "\n",
      "Filename: images/7.png     Label probs: [[0.03500297 0.26175955 0.02648429 0.20999819 0.08880901 0.23794733\n",
      "  0.09799895 0.04199972]]\n",
      "Label:  entrepreneur\n",
      "\n",
      "Filename: images/8.png     Label probs: [[2.2964552e-02 4.9980059e-01 2.0495280e-04 3.2244387e-01 2.0922747e-02\n",
      "  4.7620926e-02 5.1157442e-03 4.2764377e-02 2.2410041e-02 1.5752314e-02]]\n",
      "Label:  stock\n",
      "\n",
      "Filename: images/9.png     Label probs: [[2.4524760e-03 1.4551441e-02 8.3998188e-02 2.0518406e-01 3.1962883e-04\n",
      "  3.8179446e-02 3.4181415e-03 4.9174973e-03 1.3455694e-03 5.3174677e-03\n",
      "  6.3294148e-01 4.5679542e-03 2.8066768e-03]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/10.png     Label probs: [[0.04404779 0.06625853 0.05077882 0.05191375 0.14717154 0.4726578\n",
      "  0.137583   0.00420949 0.02537918]]\n",
      "Label:  brand\n",
      "\n",
      "Filename: images/11.png     Label probs: [[0.06177574 0.02354315 0.01153158 0.00287416 0.01766795 0.00352134\n",
      "  0.03194825 0.8342143  0.00718743 0.00573613]]\n",
      "Label:  storefront\n",
      "\n",
      "Filename: images/12.png     Label probs: [[0.01797305 0.93946385 0.00293045 0.00241538 0.00621291 0.00210216\n",
      "  0.00262499 0.00140766 0.00282771 0.02065842 0.00138335]]\n",
      "Label:  qingdao\n",
      "\n",
      "Filename: images/13.png     Label probs: [[0.23677026 0.00889968 0.01759415 0.00205864 0.00688461 0.4059969\n",
      "  0.2091061  0.11268967]]\n",
      "Label:  business\n",
      "\n",
      "Filename: images/14.png     Label probs: [[1.9069762e-03 2.7857381e-03 4.4022920e-04 1.5629233e-04 3.0511806e-05\n",
      "  4.7872911e-04 9.9401098e-01 1.0498066e-04 8.5586027e-05]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/15.png     Label probs: [[3.3217893e-04 1.8600393e-03 3.5641470e-04 7.2370619e-03 1.6037232e-03\n",
      "  1.8421556e-04 3.3021104e-01 7.3290775e-03 6.5041047e-01 4.7579163e-04]]\n",
      "Label:  montblanc\n",
      "\n",
      "Filename: images/16.png     Label probs: [[0.21909007 0.02330342 0.01321733 0.02721117 0.02744301 0.08966691\n",
      "  0.11638738 0.00661896 0.4496963  0.02736544]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/17.png     Label probs: [[0.16642873 0.001014   0.00625023 0.07262763 0.04065076 0.12071479\n",
      "  0.22128399 0.0012068  0.01682623 0.31332004 0.00963919 0.0284068\n",
      "  0.00163089]]\n",
      "Label:  investor\n",
      "\n",
      "Filename: images/18.png     Label probs: [[0.00956987 0.04640055 0.00581619 0.04732719 0.05431411 0.82246006\n",
      "  0.01411204]]\n",
      "Label:  transition\n",
      "\n",
      "Filename: images/19.png     Label probs: [[0.14724728 0.09463651 0.00740456 0.00098667 0.0068867  0.00667466\n",
      "  0.03056581 0.655487   0.05011088]]\n",
      "Label:  work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#theText = [\"a person\", \"a building\", \"animated\", \"a vehicle\", \"a landscape\"]\n",
    "#text = clip.tokenize(theText).to(device)\n",
    "\n",
    "\n",
    "for f, k in zip( filePaths, theKeywords):\n",
    "    keys = re.findall(\"\\w+\", k) \n",
    "    keys.append(\"person\")\n",
    "    image = preprocess(Image.open(f)).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize(keys).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(image, text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    print(\"Filename:\", f, \"    Label probs:\", probs)\n",
    "    print(\"Label: \", keys[np.where(probs[0] == probs[0].max())[0][0]]) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
