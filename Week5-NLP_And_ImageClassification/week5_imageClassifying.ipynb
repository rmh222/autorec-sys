{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: regex in c:\\python3\\lib\\site-packages (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\python3\\lib\\site-packages (4.62.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\python3\\lib\\site-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: colorama in c:\\python3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script ftfy.exe is installed in 'C:\\Users\\re19017\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\python3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\re19017\\appdata\\local\\temp\\pip-req-build-iuo2sz6x\n",
      "Requirement already satisfied: ftfy in c:\\users\\re19017\\appdata\\roaming\\python\\python39\\site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in c:\\python3\\lib\\site-packages (from clip==1.0) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\python3\\lib\\site-packages (from clip==1.0) (4.62.0)\n",
      "Requirement already satisfied: torch in c:\\python3\\lib\\site-packages (from clip==1.0) (1.9.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\python3\\lib\\site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\python3\\lib\\site-packages (from torch->clip==1.0) (3.7.4.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.0.1-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Requirement already satisfied: requests in c:\\python3\\lib\\site-packages (from torchvision->clip==1.0) (2.26.0)\n",
      "Requirement already satisfied: numpy in c:\\python3\\lib\\site-packages (from torchvision->clip==1.0) (1.19.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python3\\lib\\site-packages (from requests->torchvision->clip==1.0) (2021.5.30)\n",
      "Requirement already satisfied: colorama in c:\\python3\\lib\\site-packages (from tqdm->clip==1.0) (0.4.4)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py): started\n",
      "  Building wheel for clip (setup.py): finished with status 'done'\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369272 sha256=b20432469e7d744f9f195e3b0fc8e4d9580ca12d404365320c9c3b191cea2be4\n",
      "  Stored in directory: C:\\Users\\re19017\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k4vv3yen\\wheels\\c8\\e4\\e1\\11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n",
      "Successfully built clip\n",
      "Installing collected packages: torch, pillow, torchvision, clip\n",
      "Successfully installed clip-1.0 pillow-9.0.1 torch-1.11.0 torchvision-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/openai/CLIP.git 'C:\\Users\\re19017\\AppData\\Local\\Temp\\pip-req-build-iuo2sz6x'\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\re19017\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\python3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Description</th>\n",
       "      <th>Link</th>\n",
       "      <th>Article_Title</th>\n",
       "      <th>Article_URL</th>\n",
       "      <th>Article_Text</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid delivery's rapid rise has led to tension...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Dutch cities temporarily banned 10-minute deli...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/24/dutch...</td>\n",
       "      <td>['Noise, reckless cycling and blacked-out wind...</td>\n",
       "      <td>['company', 'shop', 'freeze', 'rotterdam', 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start-up conference Step in Dubai Internet City.</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>How Dubai Internet City is becoming a hub for ...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/23/how-d...</td>\n",
       "      <td>['Khazna, one of the largest data centre infra...</td>\n",
       "      <td>['khazna', 'centre', 'internet', 'data', 'incr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta CEO Mark Zuckerberg said the company's co...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Ahoy, Metamates! Meta continues rebranding eff...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/16/ahoy-...</td>\n",
       "      <td>[\"Employees at Facebook's parent company Meta ...</td>\n",
       "      <td>['employee', 'company', 'privacy', 'use', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carolyn Kaster/AP Photo</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Ahoy, Metamates! Meta continues rebranding eff...</td>\n",
       "      <td>https://www.euronews.com/next/2022/02/16/ahoy-...</td>\n",
       "      <td>[\"Employees at Facebook's parent company Meta ...</td>\n",
       "      <td>['employee', 'company', 'privacy', 'use', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Choosing a green pension could be better for t...</td>\n",
       "      <td>https://static.euronews.com/articles/stories/0...</td>\n",
       "      <td>Green pensions could be the ‘most powerful wea...</td>\n",
       "      <td>https://www.euronews.com/green/2022/02/15/gree...</td>\n",
       "      <td>['Switching to a sustainable pension could be ...</td>\n",
       "      <td>['company', 'invest', 'use', 'matter', 'pensio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Image_Description  \\\n",
       "0  Rapid delivery's rapid rise has led to tension...   \n",
       "1  Start-up conference Step in Dubai Internet City.    \n",
       "2  Meta CEO Mark Zuckerberg said the company's co...   \n",
       "3                            Carolyn Kaster/AP Photo   \n",
       "4  Choosing a green pension could be better for t...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://static.euronews.com/articles/stories/0...   \n",
       "1  https://static.euronews.com/articles/stories/0...   \n",
       "2  https://static.euronews.com/articles/stories/0...   \n",
       "3  https://static.euronews.com/articles/stories/0...   \n",
       "4  https://static.euronews.com/articles/stories/0...   \n",
       "\n",
       "                                       Article_Title  \\\n",
       "0  Dutch cities temporarily banned 10-minute deli...   \n",
       "1  How Dubai Internet City is becoming a hub for ...   \n",
       "2  Ahoy, Metamates! Meta continues rebranding eff...   \n",
       "3  Ahoy, Metamates! Meta continues rebranding eff...   \n",
       "4  Green pensions could be the ‘most powerful wea...   \n",
       "\n",
       "                                         Article_URL  \\\n",
       "0  https://www.euronews.com/next/2022/02/24/dutch...   \n",
       "1  https://www.euronews.com/next/2022/02/23/how-d...   \n",
       "2  https://www.euronews.com/next/2022/02/16/ahoy-...   \n",
       "3  https://www.euronews.com/next/2022/02/16/ahoy-...   \n",
       "4  https://www.euronews.com/green/2022/02/15/gree...   \n",
       "\n",
       "                                        Article_Text  \\\n",
       "0  ['Noise, reckless cycling and blacked-out wind...   \n",
       "1  ['Khazna, one of the largest data centre infra...   \n",
       "2  [\"Employees at Facebook's parent company Meta ...   \n",
       "3  [\"Employees at Facebook's parent company Meta ...   \n",
       "4  ['Switching to a sustainable pension could be ...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  ['company', 'shop', 'freeze', 'rotterdam', 'da...  \n",
       "1  ['khazna', 'centre', 'internet', 'data', 'incr...  \n",
       "2  ['employee', 'company', 'privacy', 'use', 'met...  \n",
       "3  ['employee', 'company', 'privacy', 'use', 'met...  \n",
       "4  ['company', 'invest', 'use', 'matter', 'pensio...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('week5.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "theImages = []\n",
    "theKeywords = [] \n",
    "sample = dataset.sample(20)\n",
    "for imagepath, key in zip( sample[\"Link\"], sample['Keywords'] ) :\n",
    "    #print(\\\"Image: \\\", imagepath)\n",
    "    req = urllib.request.urlopen(imagepath)\n",
    "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "    im = cv2.imdecode(arr, -1)\n",
    "    theImages.append(im)\n",
    "    theKeywords.append(key)\n",
    "    time.sleep(3)\n",
    "\n",
    "filePaths = []\n",
    "for i in range(len(theImages)):\n",
    "    if theImages[i] is not None:\n",
    "        fn = 'images/' + str(i) + '.png'\n",
    "        filePaths.append(fn)\n",
    "        #print(fn, theImages[i])\n",
    "        cv2.imwrite(fn, theImages[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['child',\n",
       " 'furniture',\n",
       " 'company',\n",
       " 'recycle',\n",
       " 'vanbriel',\n",
       " 'product',\n",
       " 'planet',\n",
       " 'business',\n",
       " 'joris',\n",
       " 'toy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(\"\\w+\", theKeywords[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.01665869 0.19420391 0.02826662 0.00902828 0.28671438 0.08108789\n",
      "  0.03962763 0.02636237 0.2253054  0.0331996  0.05954532]]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "keys = re.findall(\"\\w+\", theKeywords[0]) \n",
    "keys.append(\"person\")\n",
    "image = preprocess(Image.open(filePaths[0])).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(keys).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(probs)\n",
    "np.where(probs[0] == probs[0].max())[0][0]\n",
    "theText = [\"a person\", \"a dog\", \"a cat\"]\n",
    "theText[np.where(probs[0] == probs[0].max())[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/0.png',\n",
       " 'images/1.png',\n",
       " 'images/10.png',\n",
       " 'images/100.png',\n",
       " 'images/101.png',\n",
       " 'images/102.png',\n",
       " 'images/103.png',\n",
       " 'images/104.png',\n",
       " 'images/105.png',\n",
       " 'images/106.png',\n",
       " 'images/107.png',\n",
       " 'images/108.png',\n",
       " 'images/109.png',\n",
       " 'images/11.png',\n",
       " 'images/110.png',\n",
       " 'images/111.png',\n",
       " 'images/112.png',\n",
       " 'images/113.png',\n",
       " 'images/114.png',\n",
       " 'images/115.png',\n",
       " 'images/116.png',\n",
       " 'images/12.png',\n",
       " 'images/13.png',\n",
       " 'images/14.png',\n",
       " 'images/15.png',\n",
       " 'images/16.png',\n",
       " 'images/17.png',\n",
       " 'images/18.png',\n",
       " 'images/19.png',\n",
       " 'images/2.png',\n",
       " 'images/21.png',\n",
       " 'images/22.png',\n",
       " 'images/23.png',\n",
       " 'images/24.png',\n",
       " 'images/25.png',\n",
       " 'images/26.png',\n",
       " 'images/27.png',\n",
       " 'images/28.png',\n",
       " 'images/29.png',\n",
       " 'images/30.png',\n",
       " 'images/31.png',\n",
       " 'images/32.png',\n",
       " 'images/33.png',\n",
       " 'images/34.png',\n",
       " 'images/35.png',\n",
       " 'images/36.png',\n",
       " 'images/37.png',\n",
       " 'images/38.png',\n",
       " 'images/39.png',\n",
       " 'images/4.png',\n",
       " 'images/40.png',\n",
       " 'images/41.png',\n",
       " 'images/42.png',\n",
       " 'images/43.png',\n",
       " 'images/44.png',\n",
       " 'images/45.png',\n",
       " 'images/46.png',\n",
       " 'images/47.png',\n",
       " 'images/48.png',\n",
       " 'images/49.png',\n",
       " 'images/5.png',\n",
       " 'images/50.png',\n",
       " 'images/51.png',\n",
       " 'images/52.png',\n",
       " 'images/53.png',\n",
       " 'images/54.png',\n",
       " 'images/55.png',\n",
       " 'images/56.png',\n",
       " 'images/57.png',\n",
       " 'images/58.png',\n",
       " 'images/59.png',\n",
       " 'images/6.png',\n",
       " 'images/60.png',\n",
       " 'images/61.png',\n",
       " 'images/62.png',\n",
       " 'images/63.png',\n",
       " 'images/64.png',\n",
       " 'images/65.png',\n",
       " 'images/66.png',\n",
       " 'images/67.png',\n",
       " 'images/68.png',\n",
       " 'images/69.png',\n",
       " 'images/7.png',\n",
       " 'images/70.png',\n",
       " 'images/71.png',\n",
       " 'images/72.png',\n",
       " 'images/73.png',\n",
       " 'images/74.png',\n",
       " 'images/75.png',\n",
       " 'images/76.png',\n",
       " 'images/77.png',\n",
       " 'images/78.png',\n",
       " 'images/79.png',\n",
       " 'images/8.png',\n",
       " 'images/80.png',\n",
       " 'images/81.png',\n",
       " 'images/82.png',\n",
       " 'images/83.png',\n",
       " 'images/84.png',\n",
       " 'images/85.png',\n",
       " 'images/86.png',\n",
       " 'images/87.png',\n",
       " 'images/88.png',\n",
       " 'images/89.png',\n",
       " 'images/9.png',\n",
       " 'images/90.png',\n",
       " 'images/91.png',\n",
       " 'images/92.png',\n",
       " 'images/93.png',\n",
       " 'images/94.png',\n",
       " 'images/95.png',\n",
       " 'images/96.png',\n",
       " 'images/97.png',\n",
       " 'images/98.png',\n",
       " 'images/99.png']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageFilenames = []\n",
    "for f in os.listdir('images'):\n",
    "    imageFilenames.append('images/'+f)\n",
    "    \n",
    "imageFilenames.sort()\n",
    "imageFilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: images/0.png     Label probs: [[0.01665869 0.19420391 0.02826662 0.00902828 0.28671438 0.08108789\n",
      "  0.03962763 0.02636237 0.2253054  0.0331996  0.05954532]]\n",
      "Label:  vanbriel\n",
      "\n",
      "Filename: images/1.png     Label probs: [[0.17202117 0.19067247 0.09597183 0.17853592 0.05237311 0.17456755\n",
      "  0.09446716 0.04139081]]\n",
      "Label:  entrepreneur\n",
      "\n",
      "Filename: images/2.png     Label probs: [[0.33175248 0.03803428 0.00589781 0.008564   0.5963856  0.00891118\n",
      "  0.01045471]]\n",
      "Label:  shopper\n",
      "\n",
      "Filename: images/3.png     Label probs: [[9.72401910e-03 4.86902078e-04 9.54297304e-01 5.21288021e-03\n",
      "  9.79406293e-03 1.45723615e-02 5.91252465e-03]]\n",
      "Label:  ireland\n",
      "\n",
      "Filename: images/4.png     Label probs: [[0.05762423 0.0862273  0.05676711 0.0344808  0.07155424 0.13480136\n",
      "  0.03246328 0.12635887 0.07164997 0.2272038  0.10086897]]\n",
      "Label:  mol\n",
      "\n",
      "Filename: images/5.png     Label probs: [[0.01226546 0.30095688 0.04362405 0.07602143 0.08810082 0.28214264\n",
      "  0.07414858 0.01326635 0.00307582 0.10639806]]\n",
      "Label:  company\n",
      "\n",
      "Filename: images/6.png     Label probs: [[0.03035334 0.1245153  0.00853216 0.00345582 0.00209706 0.01378989\n",
      "  0.011443   0.7848383  0.02097508]]\n",
      "Label:  work\n",
      "\n",
      "Filename: images/7.png     Label probs: [[0.03500297 0.26175955 0.02648429 0.20999819 0.08880901 0.23794733\n",
      "  0.09799895 0.04199972]]\n",
      "Label:  entrepreneur\n",
      "\n",
      "Filename: images/8.png     Label probs: [[2.2964552e-02 4.9980059e-01 2.0495280e-04 3.2244387e-01 2.0922747e-02\n",
      "  4.7620926e-02 5.1157442e-03 4.2764377e-02 2.2410041e-02 1.5752314e-02]]\n",
      "Label:  stock\n",
      "\n",
      "Filename: images/9.png     Label probs: [[2.4524760e-03 1.4551441e-02 8.3998188e-02 2.0518406e-01 3.1962883e-04\n",
      "  3.8179446e-02 3.4181415e-03 4.9174973e-03 1.3455694e-03 5.3174677e-03\n",
      "  6.3294148e-01 4.5679542e-03 2.8066768e-03]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/10.png     Label probs: [[0.04404779 0.06625853 0.05077882 0.05191375 0.14717154 0.4726578\n",
      "  0.137583   0.00420949 0.02537918]]\n",
      "Label:  brand\n",
      "\n",
      "Filename: images/11.png     Label probs: [[0.06177574 0.02354315 0.01153158 0.00287416 0.01766795 0.00352134\n",
      "  0.03194825 0.8342143  0.00718743 0.00573613]]\n",
      "Label:  storefront\n",
      "\n",
      "Filename: images/12.png     Label probs: [[0.01797305 0.93946385 0.00293045 0.00241538 0.00621291 0.00210216\n",
      "  0.00262499 0.00140766 0.00282771 0.02065842 0.00138335]]\n",
      "Label:  qingdao\n",
      "\n",
      "Filename: images/13.png     Label probs: [[0.23677026 0.00889968 0.01759415 0.00205864 0.00688461 0.4059969\n",
      "  0.2091061  0.11268967]]\n",
      "Label:  business\n",
      "\n",
      "Filename: images/14.png     Label probs: [[1.9069762e-03 2.7857381e-03 4.4022920e-04 1.5629233e-04 3.0511806e-05\n",
      "  4.7872911e-04 9.9401098e-01 1.0498066e-04 8.5586027e-05]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/15.png     Label probs: [[3.3217893e-04 1.8600393e-03 3.5641470e-04 7.2370619e-03 1.6037232e-03\n",
      "  1.8421556e-04 3.3021104e-01 7.3290775e-03 6.5041047e-01 4.7579163e-04]]\n",
      "Label:  montblanc\n",
      "\n",
      "Filename: images/16.png     Label probs: [[0.21909007 0.02330342 0.01321733 0.02721117 0.02744301 0.08966691\n",
      "  0.11638738 0.00661896 0.4496963  0.02736544]]\n",
      "Label:  euronews\n",
      "\n",
      "Filename: images/17.png     Label probs: [[0.16642873 0.001014   0.00625023 0.07262763 0.04065076 0.12071479\n",
      "  0.22128399 0.0012068  0.01682623 0.31332004 0.00963919 0.0284068\n",
      "  0.00163089]]\n",
      "Label:  investor\n",
      "\n",
      "Filename: images/18.png     Label probs: [[0.00956987 0.04640055 0.00581619 0.04732719 0.05431411 0.82246006\n",
      "  0.01411204]]\n",
      "Label:  transition\n",
      "\n",
      "Filename: images/19.png     Label probs: [[0.14724728 0.09463651 0.00740456 0.00098667 0.0068867  0.00667466\n",
      "  0.03056581 0.655487   0.05011088]]\n",
      "Label:  work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#theText = [\"a person\", \"a building\", \"animated\", \"a vehicle\", \"a landscape\"]\n",
    "#text = clip.tokenize(theText).to(device)\n",
    "\n",
    "\n",
    "for f, k in zip( filePaths, theKeywords):\n",
    "    keys = re.findall(\"\\w+\", k) \n",
    "    keys.append(\"person\")\n",
    "    image = preprocess(Image.open(f)).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize(keys).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(image, text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    print(\"Filename:\", f, \"    Label probs:\", probs)\n",
    "    print(\"Label: \", keys[np.where(probs[0] == probs[0].max())[0][0]]) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
